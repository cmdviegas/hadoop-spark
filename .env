# ██████╗  ██████╗ █████╗
# ██╔══██╗██╔════╝██╔══██╗
# ██║  ██║██║     ███████║
# ██║  ██║██║     ██╔══██║
# ██████╔╝╚██████╗██║  ██║
# ╚═════╝  ╚═════╝╚═╝  ╚═╝
# DEPARTAMENTO DE ENGENHARIA DE COMPUTACAO E AUTOMACAO
# UNIVERSIDADE FEDERAL DO RIO GRANDE DO NORTE, NATAL/RN
#
# (C) 2022-2025 CARLOS M D VIEGAS
# https://github.com/cmdviegas
# 

## Docker image name
# Do not change (unless you know what you're doing)
IMAGE_VER=hadoop-spark:3.5.3

## System username and password
# These values should be changed at ***build stage***
SYS_USERNAME=spark
SYS_PASSWORD=spark

## Number of worker nodes
# This value can be changed at ***running stage***
NODE_REPLICAS=2

## Memory
MEM_AM=1024 # yarn.app.mapreduce.am.resource.mb
MEM_MAP=512 # mapreduce.map.memory.mb
MEM_RED=512 # mapreduce.reduce.memory.mb

MEM_RM=2048 # yarn.nodemanager.resource.memory-mb
MEM_MAX=1536 # yarn.scheduler.maximum-allocation-mb
MEM_MIN=512 # yarn.scheduler.minimum-allocation-mb
MAX_SCHED=0.7 # yarn.scheduler.capacity.maximum-am-resource-percent

MEM_DRV=1g # spark.driver.memory
MEM_EXE=1g # spark.executor.memory

## Network
IP_RANGE="172.30.0.0/24"
IP_NODEMASTER="172.30.0.2" # first available IP in the range
