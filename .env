# ██████╗  ██████╗ █████╗
# ██╔══██╗██╔════╝██╔══██╗
# ██║  ██║██║     ███████║
# ██║  ██║██║     ██╔══██║
# ██████╔╝╚██████╗██║  ██║
# ╚═════╝  ╚═════╝╚═╝  ╚═╝
# DEPARTAMENTO DE ENGENHARIA DE COMPUTACAO E AUTOMACAO
# UNIVERSIDADE FEDERAL DO RIO GRANDE DO NORTE, NATAL/RN
#
# (C) 2024 CARLOS M D VIEGAS
# https://github.com/cmdviegas
#

SPARK_VERSION="3.5.2"
HADOOP_VERSION="3.4.0"

## System username and password
# These values should be changed at ***build stage***
SYS_USERNAME=spark
SYS_PASSWORD=spark

## Number of worker nodes
# This value can be changed at running stage
NODE_REPLICAS=2

## Memory
MEM_AM=1024 # yarn.app.mapreduce.am.resource.mb
MEM_MAP=512 # mapreduce.map.memory.mb
MEM_RED=512 # mapreduce.reduce.memory.mb

MEM_RM=2048 # yarn.nodemanager.resource.memory-mb
MEM_MAX=1536 # yarn.scheduler.maximum-allocation-mb
MEM_MIN=512 # yarn.scheduler.minimum-allocation-mb
MAX_SCHED=0.9 # yarn.scheduler.capacity.maximum-am-resource-percent

MEM_DRV=1g # spark.driver.memory
MEM_EXE=1g # spark.executor.memory

## Network
IP_RANGE="172.30.0.0/24"
IP_NODEMASTER="172.30.0.2" # first available IP in the range
IP_HIVE="172.30.0.253" # only if hive server runs in a container separately
IP_DB="172.30.0.254" # last available IP in the range

## Docker image name
# Do not change (unless you know what you're doing)
IMAGE_VER=hadoop-spark:v6

## PostgreSQL var
# Set username, password and metastore database name
PSQL_PGUSER=postgres
PSQL_PGPASSWORD=spark
PSQL_DBNAME=hive_metastore
