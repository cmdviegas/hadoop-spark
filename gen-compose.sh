#!/bin/bash

# This script dynamically updates the docker-compose.yml file based on the number of worker nodes defined in the .env file.
# You can edit this file to suit your requirements.

# Do not execute this file directly. Instead, use: docker compose run --rm gen-compose

RED_COLOR=$(tput setaf 1)
GREEN_COLOR=$(tput setaf 2) 
YELLOW_COLOR=$(tput setaf 3)
LIGHTBLUE_COLOR=$(tput setaf 6)
RESET_COLORS=$(tput sgr0)
INFO="[${GREEN_COLOR}INFO${RESET_COLORS}]"
WARN="[${RED_COLOR}ERROR${RESET_COLORS}]"

if [ -z "$COMPOSE_CHECK" ]; then
  echo "${WARN} This script must be executed using: ${YELLOW_COLOR}docker compose run --rm gen-compose${RESET_COLORS}"
  exit 1
fi

COMPOSE_FILE="docker-compose.yml"
NUM_WORKER_NODES=${NUM_WORKER_NODES}

cat > "$COMPOSE_FILE" << EOF
# ██████╗  ██████╗ █████╗
# ██╔══██╗██╔════╝██╔══██╗
# ██║  ██║██║     ███████║
# ██║  ██║██║     ██╔══██║
# ██████╔╝╚██████╗██║  ██║
# ╚═════╝  ╚═════╝╚═╝  ╚═╝
# DEPARTAMENTO DE ENGENHARIA DE COMPUTACAO E AUTOMACAO
# UNIVERSIDADE FEDERAL DO RIO GRANDE DO NORTE, NATAL/RN
#
# (C) 2022-2025 CARLOS M D VIEGAS
# https://github.com/cmdviegas

# ⚠️ This file should not be modified manually. It is auto-generated by the gen-compose.sh script.

name: \${STACK_NAME}

networks:
  spark_network:
    name: spark_network
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.31.0.0/24

volumes:
  master:
    name: \${STACK_NAME}_master_volume
    driver: local

secrets:
  user_password:
    file: .password

services:
  gen-compose:
    image: ubuntu:24.04
    profiles: [gen-compose]
    working_dir: /workspace
    volumes:
      - ./:/workspace
    environment:
      - NUM_WORKER_NODES=\${NUM_WORKER_NODES}
      - COMPOSE_CHECK=true
    entrypoint: ["bash", "gen-compose.sh"]
    networks:
      - spark_network

EOF

if [ "$1" != "clear" ]; then

  for i in $(seq 1 $NUM_WORKER_NODES); do
    cat >> "$COMPOSE_FILE" << EOF
  worker-$i:
    image: \${IMAGE_NAME}
    container_name: \${STACK_NAME}-worker-$i
    hostname: \${STACK_NAME}-worker-$i
    tty: true
    restart: on-failure
    networks:
      - spark_network
    volumes:
      - ./myfiles:/home/\${MY_USERNAME}/myfiles
      - .env:/home/\${MY_USERNAME}/.env
    entrypoint: ["bash", "bootstrap.sh"]
    command: ["WORKER"]

EOF
  done

  cat >> "$COMPOSE_FILE" << EOF
  master:
    image: \${IMAGE_NAME}
    container_name: \${STACK_NAME}-master
    hostname: \${STACK_NAME}-master
    tty: true
    restart: on-failure
    build:
      context: .
      dockerfile: Dockerfile
      args:
        MY_USERNAME: \${MY_USERNAME}
        SPARK_VERSION: \${SPARK_VERSION}
        HADOOP_VERSION: \${HADOOP_VERSION}
        APT_MIRROR: \${APT_MIRROR}
    networks:
      - spark_network
    ports:
      - "9870:9870/tcp"
      - "8088:8088/tcp"
      - "19888:19888/tcp"
      - "18080:18080/tcp"
      - "15002:15002/tcp"
      - "8888:8888/tcp"
    volumes:
      - master:/home/\${MY_USERNAME}/
      - ./myfiles:/home/\${MY_USERNAME}/myfiles
      - .env:/home/\${MY_USERNAME}/.env
    entrypoint: ["bash", "bootstrap.sh"]
    command: ["MASTER"]
    secrets:
      - user_password
    environment:
      MY_SECRETS_FILE: /run/secrets/user_password
EOF

  printf "${INFO} ${LIGHTBLUE_COLOR}docker-compose.yml${RESET_COLORS} file successfully generated with: ${LIGHTBLUE_COLOR}%s${RESET_COLORS} worker nodes\n" "$NUM_WORKER_NODES"
  printf "${INFO} You may now start the cluster with the following command: "
  printf "${YELLOW_COLOR}docker compose build && docker compose up${RESET_COLORS}\n"
fi